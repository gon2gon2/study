{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1 이미지와 합성곱 계산\n",
    "- Convoultion(합성곱)\n",
    "- kernel(= window)의 계수를 조정하면 이미지의 sharpeness를 조정하거나 경계선 추출 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2 CNN을 사용한 이미지 분류\n",
    "- pooling으로 위치 감도 up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2.1 Fashion-MNIST\n",
    "- torchvision을 통해 데이터를 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\study\\\\pytorch\\\\first_step'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = 'c:\\\\study\\\\pytorch\\\\first_step\\\\data\\\\FashionMNIST'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to c:\\study\\pytorch\\first_step\\data\\FashionMNIST\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b199c8394b4d4d5486bd4d34dddb6ddd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting c:\\study\\pytorch\\first_step\\data\\FashionMNIST\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz to c:\\study\\pytorch\\first_step\\data\\FashionMNIST\\FashionMNIST\\raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to c:\\study\\pytorch\\first_step\\data\\FashionMNIST\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3560f65fe9814d2a9e41f5dc1ffcec39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting c:\\study\\pytorch\\first_step\\data\\FashionMNIST\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to c:\\study\\pytorch\\first_step\\data\\FashionMNIST\\FashionMNIST\\raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to c:\\study\\pytorch\\first_step\\data\\FashionMNIST\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dc0b24c10ce44218458e15dd283ce89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting c:\\study\\pytorch\\first_step\\data\\FashionMNIST\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to c:\\study\\pytorch\\first_step\\data\\FashionMNIST\\FashionMNIST\\raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to c:\\study\\pytorch\\first_step\\data\\FashionMNIST\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa74ad59c23a43b7abaab6b05f78d8b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting c:\\study\\pytorch\\first_step\\data\\FashionMNIST\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to c:\\study\\pytorch\\first_step\\data\\FashionMNIST\\FashionMNIST\\raw\n",
      "Processing...\n",
      "Done!"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:141.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import optim, nn\n",
    "from torch.utils.data import (Dataset, DataLoader, TensorDataset)\n",
    "import tqdm\n",
    "\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision import transforms\n",
    "\n",
    "# 훈련용 데이터 가져오기\n",
    "# 처음에는 PIL 형식으로 만들기 때문에 tensor로 변환 필요\n",
    "# transform.ToTensor를 사용\n",
    "fashion_mnist_train = FashionMNIST(img_dir,\n",
    "                                  train=True, download=True,\n",
    "                                  transform=transforms.ToTensor())\n",
    "# 검증용 데이터 가져오기\n",
    "fashion_mnist_test = FashionMNIST(img_dir,\n",
    "                                 train=False, download=True,\n",
    "                                 transform=transforms.ToTensor())\n",
    "\n",
    "# 배치 크기가 128인 데이터 로더 작성\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(fashion_mnist_train,\n",
    "                         batch_size = batch_size, shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(fashion_mnist_test,\n",
    "                        batch_size=batch_size,shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2.2 CNN 구축과 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (N, C, H, W)형식의 텐서를 (N, C*H*W로 늘리는 계층)\n",
    "# 합성곱 출력을 MLP에 전달할 때 필요\n",
    "class FlattenLayer(nn.Module):\n",
    "    def forward(self, x):\n",
    "        sizes = x.size()\n",
    "        return x.view(sizes[0],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5*5 커널 사용하여 처음에 32개, 다음에 64개 채널 작성\n",
    "# BatchNorm2D는 이미지용 BN\n",
    "# Dropout2D는 이미지용 dropout\n",
    "# 마지막으로 flatten layer로 전달\n",
    "conv_net = nn.Sequential(\n",
    "    nn.Conv2d(1,32,5),   # in, out, c(w or k)\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm2d(32),\n",
    "    nn.Dropout2d(0.25),\n",
    "    \n",
    "    nn.Conv2d(32,64,5),  # in, out, c(w or k)\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.Dropout2d(0.25),\n",
    "    FlattenLayer()    \n",
    ")\n",
    "\n",
    "# 최종 이미지의 출력이 어떤지 보기 위해\n",
    "# torch.ones로 만든 더미를 넣어본다.\n",
    "test_input = torch.ones(1,1,28,28)\n",
    "conv_output_size = conv_net(test_input).size()[-1]\n",
    "\n",
    "# 2층 MLP\n",
    "\n",
    "mlp = nn.Sequential(\n",
    "    nn.Linear(conv_output_size,200),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(200),\n",
    "    nn.Dropout(0.25),\n",
    "    nn.Linear(200,10)\n",
    ")\n",
    "\n",
    "# 최종 CNN\n",
    "net = nn.Sequential(\n",
    "    conv_net,\n",
    "    mlp\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가용 헬퍼 함수\n",
    "def eval_net(net, data_loader, device=\"cpu\"):\n",
    "    # Dropout, BatchNorm을 무효화\n",
    "    net.eval()\n",
    "    ys = []\n",
    "    ypreds = []\n",
    "    for x,y in data_loader:\n",
    "        # to 메서드로 계산할 device로 전송\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        # 추론만 하면 되므로 자동 미분에 필요한 처리는 off\n",
    "        with torch.no_grad():\n",
    "            _, y_pred = net(x).max(1)\n",
    "        ys.append(y)\n",
    "        ypreds.append(y_pred)\n",
    "        \n",
    "    # 미니 배치 단위의 예측 결과 등을 하나로 묶는다\n",
    "    ys = torch.cat(ys)\n",
    "    ypreds = torch.cat(ypreds)\n",
    "    # 예측 정확도 계산\n",
    "    acc = (ys == ypreds).float().sum() / len(ys)\n",
    "    return acc.item()\n",
    "\n",
    "# 훈련용 헬퍼 함수\n",
    "def train_net(net, train_loader, test_loader,\n",
    "             optimizer_cls = optim.Adam,\n",
    "             loss_fn = nn.CrossEntropyLoss(),\n",
    "             n_iter=10, device='cpu'):\n",
    "    train_losses = []\n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "    optimizer = optimizer_cls(net.parameters())\n",
    "    \n",
    "    for epoch in range(n_iter):\n",
    "        running_loss = 0.0\n",
    "        net.train()\n",
    "        n = 0\n",
    "        n_acc = 0\n",
    "        # 시간이 많이 걸리므로 tqdm을 사용해서 진행바를 표시\n",
    "        for i, (xx, yy) in tqdm.tqdm(enumerate(train_loader),\n",
    "                                    total = len(train_loader)):\n",
    "            xx = xx.to(device)\n",
    "            yy = yy.to(device)\n",
    "            h = net(xx)\n",
    "            loss = loss_fn(h, yy)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            n += len(xx)\n",
    "            _, y_pred = h.max(1)\n",
    "            n_acc += (yy == y_pred).float().sum().item()\n",
    "                \n",
    "        train_losses.append(running_loss / i)\n",
    "        # 훈련 데이터의 예측 정확도\n",
    "        train_acc.append(n_acc / n)\n",
    "\n",
    "        # 검증 데이터의 예측 정확도\n",
    "        val_acc.append(eval_net(net,test_loader,device))\n",
    "\n",
    "        # epoch의 결과 표시\n",
    "        print(epoch, train_losses[-1], train_acc[-1],\n",
    "              val_acc[-1], flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 469/469 [00:05<00:00, 89.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.2861764794931962 0.895 0.8984999656677246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 469/469 [00:05<00:00, 90.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.2598734127723763 0.9054833333333333 0.8976999521255493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 469/469 [00:05<00:00, 89.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0.24263158930927262 0.91185 0.9018999934196472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 469/469 [00:05<00:00, 89.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 0.23024927945727977 0.9141166666666667 0.9092999696731567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 469/469 [00:05<00:00, 89.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 0.2190117982144539 0.9177 0.9088000059127808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 469/469 [00:05<00:00, 89.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 0.2114857624993365 0.92195 0.9142999649047852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 469/469 [00:05<00:00, 89.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 0.20281912325921223 0.9246833333333333 0.9162999987602234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 469/469 [00:05<00:00, 89.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 0.1938758136975205 0.9287333333333333 0.9187999963760376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 469/469 [00:05<00:00, 89.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 0.18858279332391217 0.9302666666666667 0.91839998960495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 469/469 [00:05<00:00, 89.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 0.18464954348647186 0.93145 0.9140999913215637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 469/469 [00:05<00:00, 88.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0.18160265714375892 0.9314166666666667 0.9129999876022339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 469/469 [00:05<00:00, 88.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 0.17354017940278238 0.9352833333333334 0.9159999489784241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 469/469 [00:05<00:00, 89.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 0.17080814300630337 0.9357833333333333 0.917199969291687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 469/469 [00:05<00:00, 87.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 0.16501609286150107 0.9386166666666667 0.9187999963760376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 469/469 [00:05<00:00, 88.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 0.15885682551301697 0.9409333333333333 0.9187999963760376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 469/469 [00:05<00:00, 87.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 0.15818589815917689 0.9401333333333334 0.9215999841690063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 469/469 [00:05<00:00, 88.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 0.15204392604402497 0.9422833333333334 0.9185000061988831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 469/469 [00:05<00:00, 89.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 0.15217460406960076 0.9429333333333333 0.918999969959259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 469/469 [00:05<00:00, 89.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 0.14909233194258478 0.94345 0.9212999939918518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 469/469 [00:05<00:00, 89.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 0.1418798974213692 0.9464666666666667 0.920699954032898\n",
      "Wall time: 1min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "net.to(\"cuda:0\")\n",
    "train_net(net,train_loader, test_loader, n_iter=20,\n",
    "         device='cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.3 전이학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FashionMNIST', 'taco_and_burrito']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(os.path.join(os.getcwd(),'data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_dir = 'c:\\\\study\\\\pytorch\\\\first_step\\\\data\\\\taco_and_burrito'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder # 폴더명을 레이블 명으로 사용\n",
    "from torchvision import transforms\n",
    "\n",
    "train_imgs = ImageFolder(tab_dir+'/train/',\n",
    "                        transform=transforms.Compose([\n",
    "                            transforms.RandomCrop(224),\n",
    "                            transforms.ToTensor()]\n",
    "                        ))\n",
    "\n",
    "test_imgs = ImageFolder(tab_dir+'/test/',\n",
    "                        transform=transforms.Compose([\n",
    "                            transforms.RandomCrop(224),\n",
    "                            transforms.ToTensor()]\n",
    "                        ))\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(\n",
    "    train_imgs, batch_size=32, shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_imgs, batch_size=32, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['burrito', 'taco']\n"
     ]
    }
   ],
   "source": [
    "print(train_imgs.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'burrito': 0, 'taco': 1}\n"
     ]
    }
   ],
   "source": [
    "print(train_imgs.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to C:\\Users\\fizz5/.cache\\torch\\hub\\checkpoints\\resnet18-5c106cde.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "770608a1dcbf4f2f94a1559b5f98e460",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=46827520.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "\n",
    "# 사전 학습이 완료된 resnet18 불러오기\n",
    "net = models.resnet18(pretrained=True)\n",
    "\n",
    "# 모든 파라미터를 미분 대상에서 제외\n",
    "for p in net.parameters():\n",
    "    p.requires_grad = False\n",
    "    \n",
    "# 마지막 선형 계층을 변형한다\n",
    "fc_input_dim = net.fc.in_features\n",
    "net.fc = nn.Linear(fc_input_dim, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_net(net, data_loader, device='cpu'):\n",
    "    # dropout과 BN 무효화\n",
    "    net.eval()\n",
    "    ys = []\n",
    "    ypreds = []\n",
    "    for x,y in data_loader:\n",
    "        # to 메서드로 계산한 디바이스로 이동\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        # 확률이 가장 큰 놈으로 분류\n",
    "        # 추론만 할 것이니 자동미분 off\n",
    "        with torch.no_grad():\n",
    "            _, y_pred = net(x).max(1)\n",
    "        ys.append(y)\n",
    "        ypreds.append(y_pred)\n",
    "    # 미니 배치단위의 예측 결과 등을 하나로 묶는다\n",
    "    ys = torch.cat(ys)\n",
    "    ypreds = torch.cat(ypreds)\n",
    "    # 예측 정확도\n",
    "    acc = (ys==ypreds).float().sum() / len(ys)\n",
    "    return acc.item()\n",
    "\n",
    "def train_net(net, train_loader, test_loader, only_fc=True,\n",
    "              optimizer_cls = optim.Adam,\n",
    "              loss_fn = nn.CrossEntropyLoss(),\n",
    "              n_iter=10, device='cpu'):\n",
    "    train_losses = []\n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "    if only_fc: # 마지막 선형 계층의 파라미터만 optimizer에 전달\n",
    "        optimizer = optimizer_cls(net.fc.parameters())\n",
    "    else:\n",
    "        optimizer = optimizer_cls(net.parameters())\n",
    "    for epoch in range(n_iter):\n",
    "        running_loss = 0.0   # 에폭마다 초기화\n",
    "        net.train()\n",
    "        n = 0\n",
    "        n_acc = 0\n",
    "        # 시간이 많이 걸리므로 tqdm 사용\n",
    "        for i, (xx, yy) in tqdm.tqdm(enumerate(train_loader),\n",
    "        total = len(train_loader)):\n",
    "            xx = xx.to(device)\n",
    "            yy = yy.to(device)\n",
    "            h = net(xx)\n",
    "            loss = loss_fn(h, yy)   # minibath에서의 loss를 계산\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()  # 전체 에폭에 대한 loss를 구하기 위해\n",
    "            n += len(xx)                 # 매 mini-batch마다 계속 더해준다\n",
    "            _, y_pred = h.max(1)\n",
    "            n_acc += (yy == y_pred).float().sum().item()\n",
    "        train_losses.append(running_loss / i)\n",
    "        # 훈련 데이터의 예측 정확도   # n: 학습에 사용한 x의 갯수 \n",
    "        train_acc.append(n_acc / n)  # n_acc: 매 n마다 더해진 정확도\n",
    "        \n",
    "        # 검증 데이터의 예측 정확도\n",
    "        val_acc.append(eval_net(net, test_loader, device))\n",
    "        \n",
    "        # epoch의 결과 표시\n",
    "        print('{0}번째 epoch \\n학습 손실{1} \\n학습 정확도{2} \\n검증 정확도{3}'.format(epoch, train_losses[-1],train_acc[-1],val_acc[-1]),flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:02<00:00, 11.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0번째 epoch \n",
      "학습 손실0.41252379390326416 \n",
      "학습 정확도0.8370786516853933 \n",
      " 검증 정확도0.8166667222976685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:01<00:00, 11.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1번째 epoch \n",
      "학습 손실0.37892566892233764 \n",
      "학습 정확도0.8637640449438202 \n",
      " 검증 정확도0.7666667103767395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:02<00:00, 11.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2번째 epoch \n",
      "학습 손실0.38755379007621243 \n",
      "학습 정확도0.8216292134831461 \n",
      " 검증 정확도0.7666667103767395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:01<00:00, 11.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3번째 epoch \n",
      "학습 손실0.3458373194391077 \n",
      "학습 정확도0.8693820224719101 \n",
      " 검증 정확도0.8000000715255737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:01<00:00, 11.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4번째 epoch \n",
      "학습 손실0.35153055732900446 \n",
      "학습 정확도0.8595505617977528 \n",
      " 검증 정확도0.8333333730697632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:01<00:00, 11.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5번째 epoch \n",
      "학습 손실0.31995826214551926 \n",
      "학습 정확도0.8679775280898876 \n",
      " 검증 정확도0.9000000357627869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:02<00:00, 11.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6번째 epoch \n",
      "학습 손실0.33104736425659875 \n",
      "학습 정확도0.8637640449438202 \n",
      " 검증 정확도0.8500000238418579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:01<00:00, 11.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7번째 epoch \n",
      "학습 손실0.3649244809692556 \n",
      "학습 정확도0.8525280898876404 \n",
      " 검증 정확도0.8166667222976685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:01<00:00, 11.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8번째 epoch \n",
      "학습 손실0.3254976767030629 \n",
      "학습 정확도0.8806179775280899 \n",
      " 검증 정확도0.8500000238418579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:01<00:00, 11.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9번째 epoch \n",
      "학습 손실0.3187155472961339 \n",
      "학습 정확도0.8637640449438202 \n",
      " 검증 정확도0.8333333730697632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:02<00:00, 11.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10번째 epoch \n",
      "학습 손실0.324679781767455 \n",
      "학습 정확도0.8679775280898876 \n",
      " 검증 정확도0.8666667342185974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:01<00:00, 11.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11번째 epoch \n",
      "학습 손실0.33799800954081793 \n",
      "학습 정확도0.8651685393258427 \n",
      " 검증 정확도0.8833333849906921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:01<00:00, 11.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12번째 epoch \n",
      "학습 손실0.32467173649506137 \n",
      "학습 정확도0.8679775280898876 \n",
      " 검증 정확도0.9000000357627869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:01<00:00, 11.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13번째 epoch \n",
      "학습 손실0.3048193028027361 \n",
      "학습 정확도0.8806179775280899 \n",
      " 검증 정확도0.8500000238418579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:01<00:00, 11.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14번째 epoch \n",
      "학습 손실0.2945809635249051 \n",
      "학습 정확도0.8820224719101124 \n",
      " 검증 정확도0.8166667222976685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:01<00:00, 11.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15번째 epoch \n",
      "학습 손실0.28245947848666797 \n",
      "학습 정확도0.8876404494382022 \n",
      " 검증 정확도0.8833333849906921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:01<00:00, 11.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16번째 epoch \n",
      "학습 손실0.2890369560230862 \n",
      "학습 정확도0.8904494382022472 \n",
      " 검증 정확도0.8333333730697632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:01<00:00, 11.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17번째 epoch \n",
      "학습 손실0.2752950696105307 \n",
      "학습 정확도0.8806179775280899 \n",
      " 검증 정확도0.8000000715255737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:02<00:00, 11.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18번째 epoch \n",
      "학습 손실0.29297256672924216 \n",
      "학습 정확도0.8792134831460674 \n",
      " 검증 정확도0.8166667222976685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:01<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19번째 epoch \n",
      "학습 손실0.30184596980159933 \n",
      "학습 정확도0.8848314606741573 \n",
      " 검증 정확도0.9000000357627869\n"
     ]
    }
   ],
   "source": [
    "net.to('cuda:0')\n",
    "train_net(net, train_loader, test_loader, n_iter=20, device='cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 약 85~90%의 정확도\n",
    "\n",
    "- fc layer 외에는 파라미터가 변하지 않아 불필요한 연산을 반복하게 된다. 따라서 사전에 계산해두고 그것을 입력하는 로지스틱 회귀 모델을 훈련하는 것도 좋다\n",
    "\n",
    "- 입력한 것을 그대로 출력하는 더미 layer를 만들어 fc를 변경하는 것이 범용성이 높다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=512, out_features=2, bias=True)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten layer\n",
    "class FlattenLayer(nn.Module):\n",
    "    def forward(self, x):\n",
    "        sizes = x.size()\n",
    "        return x.view(sizes[0],-1)\n",
    "    \n",
    "    \n",
    "# 더미 레이어\n",
    "class IdentityLayer(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "    \n",
    "net = models.resnet18(pretrained=True)\n",
    "for p in net.parameters():\n",
    "    p.requires_grad = False\n",
    "net.fc = IdentityLayer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IdentityLayer()"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_net = nn.Sequential(\n",
    "    nn.Conv2d(3, 32, 5),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm2d(32),\n",
    "    \n",
    "    nn.Conv2d(32, 64, 5),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm2d(64),\n",
    "    \n",
    "    nn.Conv2d(64, 128, 5),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm2d(128),\n",
    "    FlattenLayer()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 인풋을 넣어서 output의 형태를 확인\n",
    "test_input = torch.ones(1,3,224,224)\n",
    "conv_output_size = conv_net(test_input).size()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:02<00:00,  8.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0번째 epoch \n",
      "학습 손실3.8611782030625776 \n",
      "학습 정확도0.5702247191011236 \n",
      " 검증 정확도0.5166667103767395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:02<00:00,  8.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1번째 epoch \n",
      "학습 손실5.096170127391815 \n",
      "학습 정확도0.598314606741573 \n",
      " 검증 정확도0.5833333730697632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:03<00:00,  7.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2번째 epoch \n",
      "학습 손실5.0405708226290615 \n",
      "학습 정확도0.6390449438202247 \n",
      " 검증 정확도0.5666667222976685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:02<00:00,  8.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3번째 epoch \n",
      "학습 손실5.136179512197321 \n",
      "학습 정확도0.6460674157303371 \n",
      " 검증 정확도0.6000000238418579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:02<00:00,  8.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4번째 epoch \n",
      "학습 손실5.739465361291712 \n",
      "학습 정확도0.6390449438202247 \n",
      " 검증 정확도0.6333333849906921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:02<00:00,  8.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5번째 epoch \n",
      "학습 손실4.725082094019109 \n",
      "학습 정확도0.6179775280898876 \n",
      " 검증 정확도0.550000011920929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:02<00:00,  8.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6번째 epoch \n",
      "학습 손실4.6435172666202895 \n",
      "학습 정확도0.6320224719101124 \n",
      " 검증 정확도0.5333333611488342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:02<00:00,  8.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7번째 epoch \n",
      "학습 손실4.14232203093442 \n",
      "학습 정확도0.6587078651685393 \n",
      " 검증 정확도0.6000000238418579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:02<00:00,  8.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8번째 epoch \n",
      "학습 손실4.633608411658894 \n",
      "학습 정확도0.6530898876404494 \n",
      " 검증 정확도0.5333333611488342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:02<00:00,  7.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9번째 epoch \n",
      "학습 손실5.31234347820282 \n",
      "학습 정확도0.6418539325842697 \n",
      " 검증 정확도0.6000000238418579\n"
     ]
    }
   ],
   "source": [
    "net = nn.Sequential(\n",
    "    conv_net,\n",
    "    nn.Linear(conv_output_size, 2)\n",
    ")\n",
    "\n",
    "net.to(\"cuda:0\")\n",
    "train_net(net, train_loader, test_loader, n_iter=10, only_fc=False,device='cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.4 CNN 회귀 모델을 사용한 이미지 해상도 향상\n",
    "- 목표 32*32 -> 128*128\n",
    "- xyz로 시작하는 인물 이름은 모두 test, 나머지는 train\n",
    "\n",
    "\n",
    "- resize는 input을 실수로 받으면 작은 애의 크기에 맞춰 조정하고 동일한 비율을 맞춰준다.\n",
    "- 튜플로 받으면 바로 조정가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ImageFolder를 확장시킴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchvision.transforms.transforms.Resize"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transforms.Resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownSizedPairImageFolder(ImageFolder):\n",
    "    def __init__(self, root, transform=None,\n",
    "                large_size=128, small_size=32, **kwds):\n",
    "        super().__init__(root, transform=transform, **kwds)\n",
    "        # ImageFolder를 확장시킴\n",
    "        self.large_resizer = transforms.Resize(large_size) # input을 \n",
    "        self.small_resizer = transforms.Resize(small_size) \n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        path, _ = self.imgs[index]\n",
    "        img = self.loader(path)\n",
    "        \n",
    "        # 읽은 이미지를 128 * 128과 32*32로 리사이즈\n",
    "        large_img = self.large_resizer(img)\n",
    "        small_img = self.small_resizer(img)\n",
    "        \n",
    "        # 기타 변환 적용\n",
    "        if self.transform is not None:\n",
    "            large_img = self.transform(large_img)\n",
    "            small_img = self.transform(small_img)\n",
    "            \n",
    "        # 32와 128 이미지 반환\n",
    "        return small_img, large_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader 작성\n",
    "- 여기서는 resize 처럼 cpu를 잡아먹는 처리가 많으므로 dataloader의 num_works를 늘린다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfw_dir = 'c:\\\\study\\\\pytorch\\\\first_step\\\\data\\\\lfw-deepfunneled'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = DownSizedPairImageFolder(lfw_dir+'\\\\train',\n",
    "                                      transform=transforms.ToTensor())\n",
    "test_data = DownSizedPairImageFolder(lfw_dir+'\\\\test',\n",
    "                                      transform=transforms.ToTensor())\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True,num_workers=4)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False,num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 작성\n",
    "- Conv2d와 ConvTransposed2d에 stride 2를 설정\n",
    "- 이 설정을 통해 MaxPool2d를 넣지 않아도 이미지 크기가 1/2가 된다\n",
    "\n",
    "\n",
    "- ConvTransposed2d는 Transposed Convolution 연산을 사용\n",
    "- convtransposed2d는 잘 모르겠다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Conv2d(3, 256, 4, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm2d(256),\n",
    "    \n",
    "    \n",
    "    nn.Conv2d(256, 512, 4, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm2d(512),\n",
    "    \n",
    "    nn.ConvTranspose2d(512, 256, 4, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm2d(256),\n",
    "    \n",
    "    nn.ConvTranspose2d(256, 128, 4, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm2d(128),\n",
    "    \n",
    "    nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm2d(64),\n",
    "    \n",
    "    nn.ConvTranspose2d(64, 3, 4, stride=2, padding=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PSNR 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def psnr(mse, max_v=1.0):\n",
    "    return 10 * math.log10(max_v**2/mse)\n",
    "\n",
    "# 평가 헬퍼 함수\n",
    "def eval_net(net, data_loader, device='cpu'):\n",
    "    # 평가한다 -> dropout, batchnorm 불필요 - > net.eval()로 비활성화\n",
    "    net.eval()\n",
    "    ys = []\n",
    "    ypreds = []\n",
    "    for x, y in data_loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        with torch.no_grad():\n",
    "            y_pred = net(x)\n",
    "        ys.append(y)\n",
    "        ypreds.append(y_pred)\n",
    "        print('first',ys)\n",
    "    # 미니배치 단위를 하나로 모음\n",
    "    ys = torch.cat(ys)\n",
    "    print('second',ys)\n",
    "    ypreds = torch.cat(ypreds)\n",
    "    \n",
    "    # MSE 계산\n",
    "    score = nn.functional.mse_loss(ypreds, ys).item()\n",
    "    return score\n",
    " \n",
    "#  train 헬퍼 함수가 추가로 필요한 것: test_loader, optimizer,loss_fn,iter\n",
    "def train_net(net, train_loader, test_loader, optimizer_cls=optim.Adam, n_iter=10, \n",
    "              loss_fn=nn.MSELoss(),device='cpu'):\n",
    "    train_losses = []\n",
    "    train_acc = []\n",
    "    val_acc =[]\n",
    "    optimizer = optimizer_cls(net.parameters())\n",
    "    for epoch in range(n_iter):\n",
    "        running_loss = 0.0\n",
    "        # 신경망을 훈련모드로 설정\n",
    "        net.train()\n",
    "        n=0\n",
    "        score=0\n",
    "        for i, (xx, yy) in tqdm.tqdm(enumerate(train_loader),\n",
    "                                     total=len(train_loader)):\n",
    "            xx = xx.to(device)\n",
    "            yy = yy.to(device)\n",
    "            y_pred = net(xx)\n",
    "            \n",
    "            loss = loss_fn(y_pred, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            n += len(xx)\n",
    "        train_losses.append(running_loss/len(train_loader))\n",
    "        # 검증 데이터의 훈련 정확도\n",
    "        val_acc.append(eval_net(net, test_loader, device))\n",
    "        #epoch의 결과 표시\n",
    "        print('{0}번째 epoch \\n학습 손실{1} \\n학습 정확도{2} \\n검증 정확도{3}'.format(epoch, train_losses[-1],train_acc[-1],val_acc[-1]),flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-90-0bd1b8fc667d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cuda:0'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_net\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'cuda:0'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-89-ade9f4064e02>\u001b[0m in \u001b[0;36mtrain_net\u001b[1;34m(net, train_loader, test_loader, optimizer_cls, n_iter, loss_fn, device)\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0mscore\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         for i, (xx, yy) in tqdm.tqdm(enumerate(train_loader),\n\u001b[0m\u001b[0;32m     42\u001b[0m                                      total=len(train_loader)):\n\u001b[0;32m     43\u001b[0m             \u001b[0mxx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    350\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    292\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_SingleProcessDataLoaderIter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 294\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0m_MultiProcessingDataLoaderIter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    295\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m    799\u001b[0m             \u001b[1;31m#     before it starts, and __del__ tries to join but will get:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    800\u001b[0m             \u001b[1;31m#     AssertionError: can only join a started process.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 801\u001b[1;33m             \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    802\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_index_queues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_queue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    803\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\multiprocessing\\process.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    110\u001b[0m                \u001b[1;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    221\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpopen_spawn_win32\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m     \u001b[1;32mclass\u001b[0m \u001b[0mSpawnContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\multiprocessing\\popen_spawn_win32.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m                 \u001b[0mset_spawning_popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\multiprocessing\\reduction.py\u001b[0m in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;34m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[0mForkingPickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
     ]
    }
   ],
   "source": [
    "net.to('cuda:0')\n",
    "train_net(net, train_loader, test_loader, device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.5 DCGAN을 사용한 이미지 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
